{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit ('base': conda)",
      "metadata": {
        "interpreter": {
          "hash": "3fa126f4b0a9b797a967ff948bb2b3f1230e77355ff8c9d30e6f0af6fbba1830"
        }
      }
    },
    "colab": {
      "name": "new1122.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICUpzeJeAyj2",
        "outputId": "f878511c-c19d-4c00-fcf2-e1e1ca9a4252"
      },
      "source": [
        "# if you want to use on COLAB upload PDF files to your drive and set patth correctly my folder is \"pdfs\"\r\n",
        "# else commend this cell\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "!cp drive/MyDrive/pdfs/test.pdf test.pdf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn6_9Ve6KDdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6e9eeb-ec48-4a1f-9168-531ac01fe52c"
      },
      "source": [
        "!pip install pytesseract pdf2image langdetect\r\n",
        "!pip install opencv-python==4.5.1.48\r\n",
        "!sudo apt install tesseract-ocr\r\n",
        "!apt-get install poppler-utils\r\n",
        "!apt-get install tesseract-ocr-fra"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/a4e9fc8a93c1318540e8de6d8d4beb5749b7960388a7c7f27799fc2dd016/pytesseract-0.3.7.tar.gz\n",
            "Collecting pdf2image\n",
            "  Downloading https://files.pythonhosted.org/packages/03/62/089030fd16ab3e5c245315d63c80b29250b8f9e4579b5a09306eb7e7539c/pdf2image-1.14.0-py3-none-any.whl\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: pytesseract, langdetect\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13945 sha256=8e5d854916cdea33cf29fbf05537efb96af6c6f284f0f5f9844d9be91a855289\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/20/7e/1dd0daad1575d5260916bb1e9781246430647adaef4b3ca3b3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp37-none-any.whl size=993193 sha256=40a380b1c4c074cfa34e90a39c504815d4ab3de60a67f407b79ce7d4a02d2ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "Successfully built pytesseract langdetect\n",
            "Installing collected packages: pytesseract, pdf2image, langdetect\n",
            "Successfully installed langdetect-1.0.8 pdf2image-1.14.0 pytesseract-0.3.7\n",
            "Collecting opencv-python==4.5.1.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/13/192104516c4a3d92dc6b5e106ffcfbf0fe35f3c4faa49650205ff652af72/opencv_python-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (50.4MB)\n",
            "\u001b[K     |████████████████████████████████| 50.4MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.1.48) (1.19.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-4.5.1.48\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,687 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 154 kB of archives.\n",
            "After this operation, 613 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.12 [154 kB]\n",
            "Fetched 154 kB in 0s (357 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 161022 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Setting up poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-fra\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 527 kB of archives.\n",
            "After this operation, 1,145 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-fra all 4.00~git24-0e00fe6-1.2 [527 kB]\n",
            "Fetched 527 kB in 1s (915 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-fra.\n",
            "(Reading database ... 161050 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-fra_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-fra (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-fra (4.00~git24-0e00fe6-1.2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zxAakK_HMM"
      },
      "source": [
        "from pdf2image import convert_from_path \n",
        "from pytesseract import Output \n",
        "from langdetect import detect\n",
        "from PIL import Image \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pytesseract \n",
        "import sys \n",
        "import cv2\n",
        "import os \n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BNwHq5SfEGM"
      },
      "source": [
        "# !ls"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EirOpaQvTDJ"
      },
      "source": [
        "def pdf_to_images(PDF_file) :\r\n",
        "    pages = convert_from_path(PDF_file, 300)  # DPI\r\n",
        "    image_counter = 1\r\n",
        "    for page in pages:\r\n",
        "      filename = PDF_file+\"_\"+str(image_counter)+\".jpg\"\r\n",
        "      page.save(filename, 'JPEG') \r\n",
        "      image_counter += 1\r\n",
        "    return pages\r\n",
        "\r\n",
        "def is_french(stringx) :\r\n",
        "    try :\r\n",
        "        if detect(stringx.lower()) == 'fr' :\r\n",
        "            return True\r\n",
        "    except :\r\n",
        "        return False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwxnhd5bN9G0"
      },
      "source": [
        "################################# We can adapt this code to pipeline############################################\r\n",
        "        # text_list = text_to_list(text)\r\n",
        "        # for line in text_list :\r\n",
        "        #   if is_french(line) or line.startswith('Artic') or line.startswith('§')  :\r\n",
        "        #     # if is_french(line) or line.startswith('Artic')  :\r\n",
        "        #     fr_list.append(line.replace('\\n',' '))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi8meTYkzeuo"
      },
      "source": [
        "##### Functions for the Pipeline start here #####\r\n",
        "# 1 - call English NLP and store results to a variable (because it finds § symbol perfectly)\r\n",
        "def en_nlp_for_symbol(filename):  \r\n",
        "  d = pytesseract.image_to_data(filename, output_type=Output.DICT)\r\n",
        "  return d.copy()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hvo4bgFmpzs"
      },
      "source": [
        "# 2 - call French NLP and store results to another variable\r\n",
        "def fr_nlp_for_symbol(filename):  \r\n",
        "  d = pytesseract.image_to_data(filename, output_type=Output.DICT, lang=\"fra\")\r\n",
        "  return d.copy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puv_2NaBqPF-"
      },
      "source": [
        "### if you like you can SAVE and SEE boxed PDF image for fr_nlp and en_nlp USE this code ###\r\n",
        "### n_boxes = len(d['level'])\r\n",
        "### for i in range(n_boxes):\r\n",
        "###   if(d['text'][i] != \"\"):\r\n",
        "###     (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\r\n",
        "###     cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\r\n",
        "### cv2.imwrite('orhan2.png', img) ###"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdhJLrV87yrL"
      },
      "source": [
        "# 3 - from English NLP results, system collect all § symbols coordinates and index info in a list\r\n",
        "def info_from_en_nlp_symbol(en_nlp, symbol=\"§\"):\r\n",
        "  pos_list=[]         # list has records in a tuple (index of English NLP, [coordinates,top,left,...])    \r\n",
        "  for t in range(len(en_nlp['text'])):\r\n",
        "    if symbol in en_nlp['text'][t]:\r\n",
        "      pos_list.append([t,[en_nlp['left'][t], en_nlp['top'][t], en_nlp['width'][t], en_nlp['height'][t]]])\r\n",
        "  return pos_list"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx8gzW9oTQDd"
      },
      "source": [
        "# 4 - match all § symbols coordinates with French NLP results and make a list\r\n",
        "def match_lists_en_and_fr_nlps(fr_nlp,pos_list, tolerans=1):   # give one pixel tolerans to match Fr and En NLPs\r\n",
        "  match_list=[]  # x[0] = left ,  x[1] = top , x[2] = width , x[3] = height ,\r\n",
        "  for k in pos_list:#for k,(a,x) in enumerate(pos_list):\r\n",
        "    for l0 in range(len(fr_nlp[\"left\"])):  \r\n",
        "      if ( fr_nlp[\"left\"][l0] + tolerans > k[1][0] ) and ( fr_nlp[\"left\"][l0] - tolerans < k[1][0] ):\r\n",
        "        if ( fr_nlp[\"top\"][l0] + tolerans > k[1][1] ) and ( fr_nlp[\"top\"][l0] - tolerans < k[1][1] ):\r\n",
        "          if ( fr_nlp[\"width\"][l0] + tolerans > k[1][2] ) and ( fr_nlp[\"width\"][l0] - tolerans < k[1][2] ):\r\n",
        "            if ( fr_nlp[\"height\"][l0] + tolerans > k[1][3] ) and ( fr_nlp[\"height\"][l0] - tolerans < k[1][3] ):            \r\n",
        "              match_list.append([l0,[fr_nlp['left'][l0], fr_nlp['top'][l0], fr_nlp['width'][l0], fr_nlp['height'][l0]]])#print(fr_nlp[\"text\"][l0],\" , index = \",l0,fr_nlp[\"left\"][l0],fr_nlp[\"top\"][l0],fr_nlp[\"width\"][l0],fr_nlp[\"height\"][l0])\r\n",
        "  return match_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ORYNJrVuL0"
      },
      "source": [
        "# 5 - Delete all duplicates from matched boxes list\r\n",
        "def delete_dublicates_from_list(match_list):\r\n",
        "  delete_list=[]\r\n",
        "  for k in match_list:\r\n",
        "    cont_list=[]\r\n",
        "    for k1 in match_list:\r\n",
        "      if k[1]==k1[1]:\r\n",
        "        cont_list.append(k1[0])\r\n",
        "    for element in cont_list:\r\n",
        "      if max(cont_list)!= element: \r\n",
        "        delete_list.append(element)\r\n",
        "  for d in list(dict.fromkeys(delete_list)):\r\n",
        "    for m in match_list:\r\n",
        "      if m[0] == d:\r\n",
        "        match_list.pop(match_list.index(m))  # print(len(match_list),match_list)\r\n",
        "  return match_list"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bqAe2Sg6qJh"
      },
      "source": [
        "# 7 - call is French function to filter to get just French results\r\n",
        "def df_fr_sentences(df_fr):\r\n",
        "  df_fr_filtered = pd.DataFrame()\r\n",
        "  df_fr_filtered[\"id\"]=list(df_fr.index.values)\r\n",
        "  df_fr_filtered[\"fullsentence\"] =df_fr.groupby(['block_num','par_num','line_num'])['text'].transform(' '.join)\r\n",
        "  for i in range(20):\r\n",
        "    df_fr_filtered[\"fullsentence\"] = df_fr_filtered[\"fullsentence\"].replace([\"      \",\"     \",\"    \",\"   \",\"  \"],\"\")\r\n",
        "  df_fr_filtered = df_fr_filtered.drop(df_fr_filtered[df_fr_filtered[\"fullsentence\"] == \"\"].index , axis=0)\r\n",
        "  df_fr_filtered = df_fr_filtered.drop(df_fr_filtered[df_fr_filtered[\"fullsentence\"] == \" \"].index , axis=0)\r\n",
        "  nl_sen =pd.Series([is_french(x) for x in df_fr_filtered[\"fullsentence\"]])\r\n",
        "  return df_fr_filtered.loc[nl_sen.fillna(False).values]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5frIS-U6g8B"
      },
      "source": [
        "### PIPELINE OF MERGING TWO NLP RESULTS TO BE ABLE TO GET FRENCH CHARACTERSET AND § SYMBOL\r\n",
        "\r\n",
        "def fill_fr_nlp_from_en_nlp(image_name):\r\n",
        "  # 1 - call English NLP and store results to a variable (because it finds § symbol perfectly)\r\n",
        "  en_nlp = en_nlp_for_symbol(image_name) # 300 dpi is recommended for OCR image files.\r\n",
        "  df_en = pd.DataFrame(en_nlp)  \r\n",
        "\r\n",
        "  # 2 - call French NLP and store results to another variable\r\n",
        "  fr_nlp = fr_nlp_for_symbol(image_name)\r\n",
        "  df_fr = pd.DataFrame(fr_nlp)  \r\n",
        "\r\n",
        "  # 3 - from English NLP results, system collect all § symbols coordinates and index info in a list\r\n",
        "  pos_en = info_from_en_nlp_symbol(en_nlp)\r\n",
        "\r\n",
        "  # 4 - match all § symbols coordinates with French NLP results and make a list\r\n",
        "  pos_fr = match_lists_en_and_fr_nlps(fr_nlp, pos_en)\r\n",
        "\r\n",
        "  # 5 - Delete all duplicates from match list\r\n",
        "  pos_fr = delete_dublicates_from_list(pos_fr)\r\n",
        "\r\n",
        "  # 6 - Change French results with desired characters\r\n",
        "  for m in pos_fr:\r\n",
        "    df_fr[\"text\"][m[0]] = df_en[\"text\"][pos_en[pos_fr.index(m)][0]]\r\n",
        "\r\n",
        "  # 7 - call is French function to filter to get just French results\r\n",
        "  df_fr_sent = df_fr_sentences(df_fr)\r\n",
        "  \r\n",
        "  df_fr[\"id\"] = df_fr.index.values\r\n",
        "  df_fr = pd.merge(df_fr, df_fr_sent, how='inner', on=['id'])\r\n",
        "  \r\n",
        "  return df_fr#, df_fr_sent #, df_en , match_list, pos_list"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBgiEWwUuC9Y"
      },
      "source": [
        "pages = pdf_to_images(\"test.pdf\") # this cell and next cell can merge to have a function"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCo08cPRerwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af577d49-9fdc-4e72-f420-499785db10b1"
      },
      "source": [
        "df_fr_full = pd.DataFrame(columns = ['id','level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height', 'conf', 'text'])\r\n",
        "print(f\"this document has {len(pages) + 1} pages process is started...\")\r\n",
        "for page in pages:\r\n",
        "  df_fr = fill_fr_nlp_from_en_nlp(pages[0])  \r\n",
        "  del df_fr[\"page_num\"]   \r\n",
        "  df_fr[\"page_num\"] = pages.index(page) + 1 \r\n",
        "  df_fr_full = df_fr_full.append(df_fr)\r\n",
        "  print(f\"{pages.index(page) + 1}. page is finished\")\r\n",
        "df_fr_full = df_fr_full.reset_index(drop=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this document has 8 pages process is started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1. page is finished\n",
            "2. page is finished\n",
            "3. page is finished\n",
            "4. page is finished\n",
            "5. page is finished\n",
            "6. page is finished\n",
            "7. page is finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpSmCu5RJ_zN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "a4c95c57-3ccd-48fd-b5d2-2b69bb1c75c0"
      },
      "source": [
        "df_fr_full"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>level</th>\n",
              "      <th>page_num</th>\n",
              "      <th>block_num</th>\n",
              "      <th>par_num</th>\n",
              "      <th>line_num</th>\n",
              "      <th>word_num</th>\n",
              "      <th>left</th>\n",
              "      <th>top</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>conf</th>\n",
              "      <th>text</th>\n",
              "      <th>fullsentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>621</td>\n",
              "      <td>354</td>\n",
              "      <td>302</td>\n",
              "      <td>32</td>\n",
              "      <td>-1</td>\n",
              "      <td></td>\n",
              "      <td>COLLECTIEVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>621</td>\n",
              "      <td>354</td>\n",
              "      <td>302</td>\n",
              "      <td>32</td>\n",
              "      <td>90</td>\n",
              "      <td>COLLECTIEVE</td>\n",
              "      <td>COLLECTIEVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>800</td>\n",
              "      <td>529</td>\n",
              "      <td>202</td>\n",
              "      <td>32</td>\n",
              "      <td>91</td>\n",
              "      <td>PARITAIR</td>\n",
              "      <td>HET AANVULLENDE PARITAIR COMITE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>114</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1307</td>\n",
              "      <td>354</td>\n",
              "      <td>851</td>\n",
              "      <td>33</td>\n",
              "      <td>-1</td>\n",
              "      <td></td>\n",
              "      <td>CONVENTION COLLECTIVE DE TRAVAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>115</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1307</td>\n",
              "      <td>354</td>\n",
              "      <td>286</td>\n",
              "      <td>33</td>\n",
              "      <td>95</td>\n",
              "      <td>CONVENTION</td>\n",
              "      <td>CONVENTION COLLECTIVE DE TRAVAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1780</th>\n",
              "      <td>659</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1395</td>\n",
              "      <td>3182</td>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "      <td>96</td>\n",
              "      <td>du</td>\n",
              "      <td>du régime de chômage avec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1781</th>\n",
              "      <td>660</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1457</td>\n",
              "      <td>3182</td>\n",
              "      <td>130</td>\n",
              "      <td>41</td>\n",
              "      <td>96</td>\n",
              "      <td>régime</td>\n",
              "      <td>du régime de chômage avec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>661</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1602</td>\n",
              "      <td>3183</td>\n",
              "      <td>46</td>\n",
              "      <td>33</td>\n",
              "      <td>95</td>\n",
              "      <td>de</td>\n",
              "      <td>du régime de chômage avec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1783</th>\n",
              "      <td>662</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1664</td>\n",
              "      <td>3183</td>\n",
              "      <td>177</td>\n",
              "      <td>41</td>\n",
              "      <td>95</td>\n",
              "      <td>chômage</td>\n",
              "      <td>du régime de chômage avec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>663</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1856</td>\n",
              "      <td>3191</td>\n",
              "      <td>90</td>\n",
              "      <td>24</td>\n",
              "      <td>96</td>\n",
              "      <td>avec</td>\n",
              "      <td>du régime de chômage avec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1785 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id level page_num  ... conf         text                       fullsentence\n",
              "0      22     4        1  ...   -1                                     COLLECTIEVE\n",
              "1      23     5        1  ...   90  COLLECTIEVE                        COLLECTIEVE\n",
              "2      37     5        1  ...   91     PARITAIR    HET AANVULLENDE PARITAIR COMITE\n",
              "3     114     4        1  ...   -1                CONVENTION COLLECTIVE DE TRAVAIL\n",
              "4     115     5        1  ...   95   CONVENTION   CONVENTION COLLECTIVE DE TRAVAIL\n",
              "...   ...   ...      ...  ...  ...          ...                                ...\n",
              "1780  659     5        7  ...   96           du          du régime de chômage avec\n",
              "1781  660     5        7  ...   96       régime          du régime de chômage avec\n",
              "1782  661     5        7  ...   95           de          du régime de chômage avec\n",
              "1783  662     5        7  ...   95      chômage          du régime de chômage avec\n",
              "1784  663     5        7  ...   96         avec          du régime de chômage avec\n",
              "\n",
              "[1785 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snw5Z8oySXEN"
      },
      "source": [
        "##### now it is turn for this 5 last tasks #####\r\n",
        "# 1 - call structuring functions to add new columns to the dataset      # Almost finished\r\n",
        "# 2 - call storeDB function to save everything to the DB                # a few lines\r\n",
        "# 3 - call function to update DB with CLA relations and changes         # a few lines\r\n",
        "# 4 - call QnA system to save desired questions and answers to the DB   # a few lines\r\n",
        "# 5 - call API to present the project to the user                       # will take time\r\n",
        "# 6 - Presentation                                                      # will take time because you did greate job guys show it"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}